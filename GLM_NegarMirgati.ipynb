{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import module to standardize the scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Import module to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('IMDB-Movie-Data.csv') \n",
    "data2 = pd.read_csv('HousePrices_HalfMil.csv') \n",
    "data3 = pd.read_csv('abalone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid 'Could not convert string to float on dataset' error\n",
    "for column in data1.columns:\n",
    "    le = LabelEncoder()\n",
    "    data1[column] = le.fit_transform(data1[column].astype(str))\n",
    "    if data1[column].dtype == type(object):\n",
    "        data1[column] = le.fit_transform(data1[column])  #Fit label encoder and return encoded labels\n",
    "        \n",
    "for column in data2.columns:\n",
    "    le = LabelEncoder()\n",
    "    data2[column] = le.fit_transform(data2[column].astype(str))\n",
    "    if data2[column].dtype == type(object):\n",
    "        data2[column] = le.fit_transform(data2[column])\n",
    "\n",
    "for column in data3.columns:\n",
    "    le = LabelEncoder()\n",
    "    data3[column] = le.fit_transform(data3[column].astype(str))\n",
    "    if data3[column].dtype == type(object):\n",
    "        data3[column] = le.fit_transform(data3[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create instance of the standard scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the object to all the data except the Target \n",
    "scaler.fit(data1.drop('Metascore', axis=1))\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(data2.drop('Prices', axis=1))\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(data3.drop('Rings', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scaler object to conduct a transforms\n",
    "scaled_features = scaler.transform(data1.drop('Metascore',axis=1))\n",
    "\n",
    "scaled_features2 = scaler2.transform(data2.drop('Prices',axis=1))\n",
    "\n",
    "scaled_features3 = scaler3.transform(data3.drop('Rings',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the scaled features to create a data frame of features\n",
    "data_feat = pd.DataFrame(scaled_features, columns = data1.columns[:-1])\n",
    "data_feat2 = pd.DataFrame(scaled_features2, columns = data2.columns[:-1])\n",
    "data_feat3 = pd.DataFrame(scaled_features3, columns = data3.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the X and ys\n",
    "X = data_feat\n",
    "y = data1['Metascore']\n",
    "\n",
    "# Use the train_test_split() method to split the data into respective sets\n",
    "# test_size -> argument refers to the size of the test subset\n",
    "# random_state -> argument ensures guarantee that the output of Run \n",
    "# 1 will be equal to the output of Run 2, i.e. your split will be always the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "X2 = data_feat2\n",
    "y2 = data2['Prices']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=101)\n",
    "\n",
    "X3 = data_feat3\n",
    "y3 = data3['Rings']\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the X and ys\n",
    "X = data_feat\n",
    "y = data1['Metascore']\n",
    "\n",
    "# Use the train_test_split() method to split the data into respective sets\n",
    "# test_size -> argument refers to the size of the test subset\n",
    "# random_state -> argument ensures guarantee that the output of Run \n",
    "# 1 will be equal to the output of Run 2, i.e. your split will be always the same\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "X2 = data_feat2\n",
    "y2 = data2['Prices']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=101)\n",
    "\n",
    "X3 = data_feat3\n",
    "y3 = data3['Rings']\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Ordinary Least Squares -data1\n",
    "model1 = linear_model.LinearRegression()\n",
    "model2 = linear_model.LinearRegression()\n",
    "model3 = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train2, y_train2)\n",
    "model3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15851656275507797\n",
      "0.9757385773777847\n",
      "0.30421176317025533\n"
     ]
    }
   ],
   "source": [
    "pred1 = model1.predict(X_test)\n",
    "print(model1.score(X_test,y_test))\n",
    "\n",
    "pred2 = model2.predict(X_test2)\n",
    "print(model2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = model3.predict(X_test3)\n",
    "print(model3.score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 -  Ridge Regression\n",
    "reg1 = linear_model.Ridge(alpha = .5)\n",
    "reg2 = linear_model.Ridge(alpha = .5)\n",
    "reg3 = linear_model.Ridge(alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.fit(X_train, y_train)\n",
    "reg2.fit(X_train2, y_train2)\n",
    "reg3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15860090029511173\n",
      "0.9757386999384906\n",
      "0.3043174145825497\n"
     ]
    }
   ],
   "source": [
    "pred1 = reg1.predict(X_test)\n",
    "print(reg1.score(X_test,y_test))\n",
    "\n",
    "pred2 = reg2.predict(X_test2)\n",
    "print(reg2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = reg3.predict(X_test3)\n",
    "print(reg3.score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Lasso\n",
    "clf1 = linear_model.Lasso(alpha=0.1)\n",
    "clf2 = linear_model.Lasso(alpha=0.1)\n",
    "clf3 = linear_model.Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train2, y_train2)\n",
    "clf3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16034862348305415\n",
      "0.9757385195720378\n",
      "0.2968495494264458\n"
     ]
    }
   ],
   "source": [
    "pred1 = clf1.predict(X_test)\n",
    "print(clf1.score(X_test,y_test))\n",
    "\n",
    "pred2 = clf2.predict(X_test2)\n",
    "print(clf2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = clf3.predict(X_test3)\n",
    "print(clf3.score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - ElasticNet\n",
    "regr1 = linear_model.ElasticNet(random_state=0)\n",
    "regr2 = linear_model.ElasticNet(random_state=0)\n",
    "regr3 = linear_model.ElasticNet(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=0, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr1.fit(X_train, y_train)\n",
    "regr2.fit(X_train2, y_train2)\n",
    "regr3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16311953629056922\n",
      "0.8768639120645896\n",
      "0.24830225922998617\n"
     ]
    }
   ],
   "source": [
    "pred1 = regr1.predict(X_test)\n",
    "print(regr1.score(X_test,y_test))\n",
    "\n",
    "pred2 = regr2.predict(X_test2)\n",
    "print(regr2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = regr3.predict(X_test3)\n",
    "print(regr3.score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - LARS Lasso\n",
    "reg1 = linear_model.LassoLars(alpha=0.01)\n",
    "reg2 = linear_model.LassoLars(alpha=0.01)\n",
    "reg3 = linear_model.LassoLars(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLars(alpha=0.01, copy_X=True, eps=2.220446049250313e-16,\n",
       "     fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
       "     positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.fit(X_train, y_train)\n",
    "reg2.fit(X_train2, y_train2)\n",
    "reg3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "   fit_path=True, n_nonzero_coefs=1, normalize=True, positive=False,\n",
       "   precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.fit(X_train, y_train)\n",
    "reg2.fit(X_train2, y_train2)\n",
    "reg3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1409408784441687\n",
      "0.14882437954725147\n",
      "0.26432345827411863\n"
     ]
    }
   ],
   "source": [
    "pred1 = reg1.predict(X_test)\n",
    "print(reg1.score(X_test,y_test))\n",
    "\n",
    "pred2 = reg2.predict(X_test2)\n",
    "print(reg2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = reg3.predict(X_test3)\n",
    "print(reg3.score(X_test3,y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 - Least Angle Regression\n",
    "reg1 = linear_model.Lars(n_nonzero_coefs=1)\n",
    "reg2 = linear_model.Lars(n_nonzero_coefs=1)\n",
    "reg3 = linear_model.Lars(n_nonzero_coefs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "   fit_path=True, n_nonzero_coefs=1, normalize=True, positive=False,\n",
       "   precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg1.fit(X_train, y_train)\n",
    "reg2.fit(X_train2, y_train2)\n",
    "reg3.fit(X_train3, y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1409408784441687\n",
      "0.14882437954725147\n",
      "0.26432345827411863\n"
     ]
    }
   ],
   "source": [
    "pred1 = reg1.predict(X_test)\n",
    "print(reg1.score(X_test,y_test))\n",
    "\n",
    "pred2 = reg2.predict(X_test2)\n",
    "print(reg2.score(X_test2,y_test2))\n",
    "\n",
    "pred3 = reg3.predict(X_test3)\n",
    "print(reg3.score(X_test3,y_test3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
